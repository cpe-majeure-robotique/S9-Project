# Pr√©hension d'Objets avec le bras xArm7 : Du Visual Servoing Classique aux Mod√®les de Fondation Robotique

## üéØ Objectif du Projet

Ce projet explore deux approches compl√©mentaires pour la pr√©hension d'objets avec le bras robotique xArm7 :

1. **Visual Servoing Classique** : Mise en ≈ìuvre d'une approche traditionnelle de commande asservie par vision pour √©tablir une base de r√©f√©rence
2. **Mod√®le de Fondation avec LeRobot** : Utilisation d'un mod√®le pr√©-entra√Æn√© via la plateforme LeRobot de Hugging Face pour g√©n√©raliser les comp√©tences de manipulation

L'objectif est de comparer ces deux paradigmes et d'affiner les performances du mod√®le de fondation sur des objets sp√©cifiques.  

Chaque exp√©rimentation se fera **d'abord en simulation**, avant de se faire en r√©el

---

## üìù Cahier des Charges et T√¢ches Principales

### **Partie 1 : Visual Servoing Classique (Base de R√©f√©rence)**

#### 1.1 √âtude Th√©orique
- Comprendre les principes du visual servoing (IBVS - Image-Based VS ou PBVS - Position-Based VS)
- √âtudier la cin√©matique du xArm7 
- D√©finir une strat√©gie de pr√©hension bas√©e sur la d√©tection de primitives visuelles (points, contours, marqueurs ArUco, etc.)

#### 1.2 Impl√©mentation
- Cr√©er l'environnement de travail et faire un Hello World de d√©placement du bras en simulation (gazebo), puis en r√©el. 
- Mettre en place la boucle de commande asservie : acquisition d'image ‚Üí extraction de caract√©ristiques ‚Üí calcul de l'erreur ‚Üí commande articulaire
- Impl√©menter la d√©tection et la localisation d'objets (vision par ordinateur classique : OpenCV, d√©tection de contours, segmentation)
- R√©aliser des t√¢ches de pick-and-place simples avec contr√¥le de la position et de l'orientation

#### 1.3 √âvaluation
- Mesurer le taux de succ√®s de pr√©hension sur un ensemble d'objets de test
- Analyser les limites : sensibilit√© aux variations d'√©clairage, robustesse face √† l'occlusion, g√©n√©ralisation √† de nouveaux objets

---

### **Partie 2 : Mod√®le de Fondation avec LeRobot**

#### 2.1 Recherche et S√©lection du Mod√®le
- Explorer la plateforme **LeRobot** (https://github.com/huggingface/lerobot) d√©velopp√©e par Hugging Face
- √âtudier les mod√®les de fondation/VLA disponibles (ex: ACT, Diffusion Policy, VQ-BeT, OpenVLA via LeRobot)
- S√©lectionner un mod√®le adapt√© √† la pr√©hension et compatible avec l'architecture du xArm7

#### 2.2 Int√©gration et D√©ploiement
- Installer l'environnement LeRobot et ses d√©pendances
- Configurer l'interface entre LeRobot et l'API Python du xArm7
- Adapter le pipeline de perception (cam√©ra) pour correspondre au format d'entr√©e du mod√®le
- G√©n√©rer des commandes d'action (trajectoires articulaires, commande du pr√©henseur) √† partir des observations visuelles

#### 2.3 Collecte de Donn√©es avec LeRobot
- Identifier une classe d'objets "difficiles" ou sp√©cifiques √† l'environnement du laboratoire
- Utiliser les outils de t√©l√©-op√©ration de LeRobot pour collecter des d√©monstrations
- Constituer un dataset au format LeRobot (observations + actions) pour le fine-tuning
- Documenter le protocole de collecte et les m√©tadonn√©es des √©pisodes

#### 2.4 Affinement (Fine-Tuning)
- Configurer l'entra√Ænement du mod√®le sur le dataset collect√©
- Ajuster les hyperparam√®tres (learning rate, batch size, nombre d'√©poques)
- Affiner le mod√®le de fondation pour am√©liorer le taux de succ√®s sur les objets cibl√©s


---

## üõ†Ô∏è Outils et Ressources

- **Mat√©riel** : 
  - Bras robotique xArm7
  - cam√©ra RGB(-D)
  - objets de test ([dataset YCB](https://www.ycbbenchmarks.com/object-models/))
- **Logiciels** : 
  - Python, OpenCV (pour visual servoing classique)
  - LeRobot (Hugging Face) pour les mod√®les de fondation
  - API xArm Python SDK
  - ROS2 (optionnel, selon l'architecture)

